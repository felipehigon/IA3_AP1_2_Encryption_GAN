{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Encriptacion_Chat.ipynb","provenance":[],"authorship_tag":"ABX9TyMZdcAyrerr1J1jLPnVzBXl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lGXy9-EQyjRF"},"source":["# CARGA LIBRERIAS"]},{"cell_type":"code","metadata":{"id":"JshkCTXCvuqd"},"source":["import numpy as np\n","from numpy import expand_dims\n","from numpy import zeros\n","from numpy import ones\n","from numpy.random import randn\n","from numpy.random import randint\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Input, Lambda, Conv2D, MaxPooling2D, Flatten, Dropout, Reshape, Conv2DTranspose,LeakyReLU, Embedding, Concatenate, GlobalMaxPooling2D, BatchNormalization\n","import matplotlib.pyplot as plt\n","#tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4nWlyreysBA"},"source":["tf.test.gpu_device_name()\n","import timeit\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise SystemError('GPU device not found')\n","\n","def cpu():\n","  with tf.device('/cpu:0'):\n","    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n","    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n","    return tf.math.reduce_sum(net_cpu)\n","\n","def gpu():\n","  with tf.device('/device:GPU:0'):\n","    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n","    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n","    return tf.math.reduce_sum(net_gpu)\n","  \n","# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n","cpu()\n","gpu()\n","\n","# Run the op several times.\n","print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n","      '(batch x height x width x channel). Sum of ten runs.')\n","print('CPU (s):')\n","cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n","print(cpu_time)\n","print('GPU (s):')\n","gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n","print(gpu_time)\n","print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iz0P-eCJyxNd"},"source":["# CARGA MNIST"]},{"cell_type":"code","metadata":{"id":"zBJZMIRcy09i"},"source":["# Carga\n","num_classes = 10\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","\n","# Normalización\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.astype('float32') / 255\n","\n","X_train2D = np.expand_dims(X_train, -1)\n","X_test2D = np.expand_dims(X_test, -1)\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","print(' -Entradas Entrenamiento:', X_train2D.shape)\n","print(' -Entradas Test:', X_test2D.shape)\n","\n","print('Cambio de dimensiones para ajustar a la entrada de un Perceptrón:')\n","x_shape = X_train.shape\n","X_train = X_train.reshape(x_shape[0], x_shape[1]*x_shape[2])\n","X_test = X_test.reshape(len(X_test), x_shape[1]*x_shape[2])\n","print(' -Entradas Entrenamiento:', X_train.shape)\n","print(' -Entradas Test:', X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KJRjFT5Gy5LO"},"source":["# MODELO AUTOENCODER PARA GENERAR ENCRIPTACIÓN"]},{"cell_type":"code","metadata":{"id":"Kxo7W0FTy63_"},"source":["# Tamaño de nuestra representación codificada\n","# 32 Factor de compresión = 24.5 (dado que la entrada es de tamaño 784)\n","# 16 Factor de compresión = 49 (dado que la entrada es de tamaño 784)\n","# con 16 el espacio latente es mas caotico\n","\n","def AutoEncript(encoding_dim = 32):  \n","\n","# Definimos las capas para la entrada, el encoder y el decoder:\n","# Capa de entrada\n","  input_img = Input(shape=(784,), name='Input')\n","  init = 'RandomNormal'\n","\n","# Capas del encoder\n","  encoder1 = Dense(128, kernel_initializer=init, activation='relu', name='Encoder1')\n","  encoder2 = Dense(64, kernel_initializer=init,activation='relu', name='Encoder2')\n","  encoder3 = Dense(encoding_dim,kernel_initializer=init, activation='relu', name='Encoder3')\n","\n","# Capas del decoder\n","  \n","  decoder1 = Dense(64,kernel_initializer=init, activation='relu', name='Decoder1')\n","  decoder2 = Dense(128,kernel_initializer=init, activation='relu', name='Decoder2')\n","  decoder3 = Dense(784,kernel_initializer=init, activation='sigmoid', name='Decoder3')\n","\n","#       Autoencoder\n","# --------------------------\n","# \"encoded\" es la representación codificada de la entrada (cada vez más comprimida)\n","  encoded = encoder1(input_img)\n","  encoded = encoder2(encoded)\n","  encoded = encoder3(encoded)\n","\n","# \"decoded\" es la reconstrución de la entrada a partir de la entrada codificada\n","  decoded = decoder1(encoded)\n","  decoded = decoder2(decoded)\n","  decoded = decoder3(decoded)\n","\n","# Modelo que reconstruye una entrada\n","  autoencoder = tf.keras.Model(input_img, decoded)\n","\n","# Creo encoder por separado\n","  encoder = tf.keras.Model(input_img, encoded)\n","# Creo decoder por separado\n","  input_img_e = Input(shape=(encoding_dim,), name='Input_e')\n","  decoded2 = decoder1(input_img_e)\n","  decoded2 = decoder2(decoded2)\n","  decoded2 = decoder3(decoded2)\n","  decoder = tf.keras.Model(input_img_e, decoded2)\n","\n","  return autoencoder, encoder, decoder, input_img\n","\n","autoencoder1, encoder1, decoder1, input_img1 = AutoEncript(16)\n","autoencoder2, encoder2, decoder2, input_img2 = AutoEncript(16)\n","# Visualizar arquitectura y dimensiones\n","print(f\"{'*'*65}\\n\\t\\t\\tAutoencoder\\n{'*'*65}\")\n","autoencoder1.summary()\n","autoencoder2.summary()\n","encoder1.summary()\n","encoder2.summary()\n","decoder1.summary()\n","decoder2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5Qmj9azzEct"},"source":["with tf.device('/device:GPU:0'):\n","  autoencoder1.compile(optimizer='adam', loss='binary_crossentropy')\n","  hist= autoencoder1.fit(X_train, X_train,\n","                      epochs=50,\n","                      batch_size=256,\n","                      shuffle=True,\n","                      validation_data=(X_test, X_test))\n","  autoencoder2.compile(optimizer='adam', loss='binary_crossentropy')\n","  hist= autoencoder2.fit(X_train, X_train,\n","                      epochs=50,\n","                      batch_size=256,\n","                      shuffle=True,\n","                      validation_data=(X_test, X_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-V16tTTzM2o"},"source":["# COMPROBACION ESPACIO LATENTE"]},{"cell_type":"markdown","metadata":{"id":"-1cqRZjXzd4B"},"source":["- Se combinan los encoders y decoders para ver que los espacios latentes no son comunes para distintos modelos"]},{"cell_type":"code","metadata":{"id":"1pHeMwLszSIl"},"source":["# Codificamos y decodificamos algunos dígitos de ejemplo (datos de test)\n","# -----------------------\n","encoded1_imgs = encoder1.predict(X_test)\n","encoded2_imgs = encoder2.predict(X_test)\n","\n","decoded1_imgs = decoder1.predict(encoded1_imgs)\n","decoded2_imgs = decoder2.predict(encoded2_imgs)\n","\n","decoded1_2_imgs = decoder1.predict(encoded2_imgs)\n","decoded2_1_imgs = decoder2.predict(encoded1_imgs)\n"," \n","def subplot(X,encoded_imgs, decoded_imgs, n_images = 10,encoding_dim = 32):\n","  # Entrada (original)\n","    plt.subplot(3, n_images, i + 1)\n","    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n","    plt.title('Entrada')\n","    plt.axis('off')\n","\n","    # Codificación\n","    plt.subplot(3, n_images, i + 1 + n_images)\n","    plt.imshow(encoded_imgs[i].reshape(1, encoding_dim), cmap='gray')\n","    #print(encoded_imgs[i].reshape(1, encoding_dim))\n","    plt.axis('off')\n","    plt.title('Entrada codificada')\n","    \n","    # Reconstrucción\n","    plt.subplot(3, n_images, i + 1 + n_images + n_images)\n","    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n","    plt.axis('off')\n","    plt.title('Reconstrucción')\n","\n","def plot_data(X,encoded_imgs, decoded_imgs, n_images = 10,encoding_dim = 32):\n","  plt.figure(figsize=(30, 4))\n","  if n_images > 2:\n","    for i in range(n_images):\n","      subplot(X,encoded_imgs, decoded_imgs, n_images,encoding_dim)\n","\n","plot_data(X_test,encoded1_imgs,decoded1_imgs,encoding_dim=16)"],"execution_count":null,"outputs":[]}]}